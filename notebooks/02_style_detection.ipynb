{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 13:22:53.474 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'humor': 0.31414510476474533,\n",
       " 'wiki': 0.31175900380284843,\n",
       " 'proverbs': 0.06196405935426143,\n",
       " 'reuters': 0.3121318320781448}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "count_labels = collections.Counter([traindataset[i][1] for  i in range(len(traindataset))])\n",
    "{v: count_labels[v] / len(traindataset) for v in count_labels}\n",
    "# TODO ~ about 4 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naar voren komt is dat de dataset ongebalanceerd is. De verdeling van de 4 classes is niet gelijk. Het aantal zinnen met het label 'proverbs' is beduidend lager vergeleken met de andere 3 labels. De kans dat de zin het label 'humor' of 'wiki'of 'reuters' heeft is veel groter. Het model kan hierdoor niet bruikbare features leren van de groep met het label 'proverbs', het model heeft minder voorbeelden ter beschikking om van te leren. Er is hierdoor een vergrote kans van overfitting.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    \"A preprocessor with the cast_label function for adding the labels from the dictionary\"\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        if label in d.keys():\n",
    "            return d[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4929,  854,   32,   15,  499,   21, 8496,  890]], dtype=torch.int32),\n",
       " tensor([2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "preprocessor([(x, y)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 36]),\n",
       " tensor([1, 2, 1, 1, 0, 0, 0, 2, 2, 1, 1, 2, 0, 2, 1, 1, 2, 3, 3, 1, 1, 2, 0, 2,\n",
       "         0, 0, 0, 1, 0, 2, 0, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "\n",
    "metrics = [metrics.Accuracy()]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om te controleren of de uitkomst correct is gebruiken we de CrossEntropyloss. Deze is geschikt voor multiclass categorisatie. MSE kan bijvoorbeeld hier niet voor gebruiken aangezien dit juist is voor numerieke voorspellingen. Ik heb later in het notebook de addition metric (metrics = [metrics.Accuracy(), metrics.F1Score()]), omdat ik graag het verschil wil laten in de confusion matrix. \n",
    "De f1 score kijkt naar een gemiddele van de precisie en recall ( tussen 0 en 1) scores en kan worden gebruikt voor classificatie problemen. De F1 score kan gebruikt worden in ongebalanceerde datasets. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3, \n",
    "    \"dropout\": 0.1, \n",
    "    \"output_size\": 4,\n",
    "}\n",
    "from src.models import rnn\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419.09375"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset)/32 # lengte traindataset gedeeld door de batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De lengte van de traindataset is 13.411. Hierbij kun je dus 420 batches maken van 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.955"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(traindataset) + len(testdataset)) / (32*25) # de totale lengte van de dataset gedeeld door de train step en de batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De totale dataset heeft een lengte van 16.764. Om de hele datsaet te covereren zijn er 21 epochs nodig. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.76375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) / (32*25) # de totale lengte van de traindataset gedeeld door de train step en de batchsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Om de totale triandatset te coveren zijn er mnimaal 17 epochs nodig op basis van 25 train_steps.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 13:23:38.132518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-02 13:23:38.132556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-07-02 13:23:40.071 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220702-1323\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=21,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/tensorboard_nlp.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In de bovenste twee grafieken van de afbeelding zijn de test en train loss te zien. Deze zijn beide nog vrij hoog en de learning rate blijft stabiel op 1e-3 ondanks dat er een scheduler in de trainloop zit die mogelijk de learning rate kan verlagen. Daarnaast vlakt de accuracy wel iets af, echter is mijn verwachting hierbij dat het aantal epochs aan de lage kant is. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 15.0, 'Predicted'), Text(33.0, 0.5, 'Target')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je ziet hier de uitkomst tussen niet normale verdeling van de dataset. Hierbij is bijvoorbeeld de eerste cel, deze is predicted 0 en voor 80% is deze ook 0. Dit geldt dus niet voor groep 3, waarbij deze maar rond de 45% ook groep 3 voorspelt. Label 3 is de groep 'proverbs, waarbij er een veel lager aantal van is.  De dataset is dus ongebalanceerd. Een mogelijkheid hiervoor is om data augmenting te gebruiken. Hierbij gaan we dus de data kunstmatig vergroten van de group 'proverbs'. Hierbij kun je meer gewicht toekennen aan de groep 'proverbers'. Dit zal invloed hebben op de likelihood dat een punt uit een klasse wordt getrokken, doordat je van een uniforme verdeling naar een multinomiale verdeling met gecontroleerde paremeters gaat. De F1Score zorgt voor een betere verhouding. Deze wordt toegevoegd aan de metrics en nogmaals wordt de confusion matrix uitgedraaid.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "metrics = [metrics.Accuracy(), metrics.F1Score()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 10:00:33.893 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220702-1000\n",
      "100%|██████████| 25/25 [00:06<00:00,  3.97it/s]\n",
      "2022-07-02 10:00:40.869 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 1.2846 test 1.2746 metric ['0.4188', '0.2693']\n",
      "100%|██████████| 25/25 [00:02<00:00,  9.89it/s]\n",
      "2022-07-02 10:00:43.944 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 1.2676 test 1.2094 metric ['0.4175', '0.2732']\n",
      "100%|██████████| 25/25 [00:01<00:00, 13.44it/s]\n",
      "2022-07-02 10:00:46.220 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 1.2265 test 1.1916 metric ['0.4500', '0.2823']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.06it/s]\n",
      "2022-07-02 10:00:48.197 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 1.0562 test 1.1218 metric ['0.5112', '0.4040']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.59it/s]\n",
      "2022-07-02 10:00:50.054 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.9763 test 0.9095 metric ['0.5825', '0.4135']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.63it/s]\n",
      "2022-07-02 10:00:51.875 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.9017 test 0.8270 metric ['0.6062', '0.4345']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.33it/s]\n",
      "2022-07-02 10:00:53.798 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.7987 test 0.7445 metric ['0.7212', '0.5922']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.83it/s]\n",
      "2022-07-02 10:00:55.679 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.6822 test 0.6419 metric ['0.7625', '0.6067']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.01it/s]\n",
      "2022-07-02 10:00:57.575 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.6252 test 0.5476 metric ['0.8037', '0.6649']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.26it/s]\n",
      "2022-07-02 10:00:59.451 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.5710 test 0.4796 metric ['0.8313', '0.6653']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.98it/s]\n",
      "2022-07-02 10:01:01.250 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.4958 test 0.4705 metric ['0.8387', '0.7026']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.97it/s]\n",
      "2022-07-02 10:01:03.224 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.4556 test 0.5134 metric ['0.8300', '0.7294']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.53it/s]\n",
      "2022-07-02 10:01:05.172 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.4712 test 0.4723 metric ['0.8375', '0.7250']\n",
      "100%|██████████| 25/25 [00:01<00:00, 18.62it/s]\n",
      "2022-07-02 10:01:06.942 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.4323 test 0.4696 metric ['0.8337', '0.7000']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.56it/s]\n",
      "2022-07-02 10:01:08.854 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.4347 test 0.3967 metric ['0.8738', '0.7889']\n",
      "100%|██████████| 25/25 [00:01<00:00, 16.83it/s]\n",
      "2022-07-02 10:01:10.761 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.4698 test 0.4395 metric ['0.8287', '0.7162']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.43it/s]\n",
      "2022-07-02 10:01:12.612 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.4207 test 0.4063 metric ['0.8538', '0.7435']\n",
      "100%|██████████| 25/25 [00:04<00:00,  5.55it/s]\n",
      "2022-07-02 10:01:17.978 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.3018 test 0.3985 metric ['0.8600', '0.7720']\n",
      "100%|██████████| 25/25 [00:01<00:00, 12.53it/s]\n",
      "2022-07-02 10:01:20.416 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.3616 test 0.4045 metric ['0.8550', '0.7313']\n",
      "100%|██████████| 25/25 [00:01<00:00, 20.25it/s]\n",
      "2022-07-02 10:01:22.044 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.3384 test 0.3782 metric ['0.8650', '0.7822']\n",
      "100%|██████████| 25/25 [00:01<00:00, 17.25it/s]\n",
      "2022-07-02 10:01:23.937 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.3094 test 0.3588 metric ['0.8850', '0.7934']\n",
      "100%|██████████| 21/21 [00:50<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=21,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/confusion_matrix_f1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij komt naar voren dat voor dat voor target 3 in ~75% van de gevallen als een 3 wordt voorspeld. Dit is beduidend hoger dan alleen gebruik te maken van de accurcy metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierbij hebben we een nieuwe class toegevoegd in de rnn models. Dit is de AttentionNLP > hierbij zit dus een attional layer tussen de GRU en linear. Dit zorgt voor meer context in het verhaal. In eerste instantie worden de huidige parameters ingesteld, hierbij wel de toevoeging van de F1 score.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnn.AttentionNLP(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 13:04:19.036 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220702-1304\n",
      "100%|██████████| 45/45 [00:13<00:00,  3.39it/s]\n",
      "2022-07-02 13:04:33.792 | INFO     | src.training.train_model:trainloop:164 - Epoch 0 train 0.9768 test 0.6838 metric ['0.7701', '0.6264']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.72it/s]\n",
      "2022-07-02 13:04:41.122 | INFO     | src.training.train_model:trainloop:164 - Epoch 1 train 0.6683 test 0.6128 metric ['0.7812', '0.6954']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.13it/s]\n",
      "2022-07-02 13:04:48.183 | INFO     | src.training.train_model:trainloop:164 - Epoch 2 train 0.5095 test 0.5249 metric ['0.8167', '0.6817']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.64it/s]\n",
      "2022-07-02 13:04:55.571 | INFO     | src.training.train_model:trainloop:164 - Epoch 3 train 0.4942 test 0.4773 metric ['0.8326', '0.7465']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
      "2022-07-02 13:05:02.637 | INFO     | src.training.train_model:trainloop:164 - Epoch 4 train 0.4619 test 0.4154 metric ['0.8667', '0.8160']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.10it/s]\n",
      "2022-07-02 13:05:09.746 | INFO     | src.training.train_model:trainloop:164 - Epoch 5 train 0.4126 test 0.4546 metric ['0.8396', '0.7668']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.55it/s]\n",
      "2022-07-02 13:05:16.549 | INFO     | src.training.train_model:trainloop:164 - Epoch 6 train 0.4456 test 0.4058 metric ['0.8625', '0.7477']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.83it/s]\n",
      "2022-07-02 13:05:23.872 | INFO     | src.training.train_model:trainloop:164 - Epoch 7 train 0.3355 test 0.3738 metric ['0.8771', '0.8070']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.60it/s]\n",
      "2022-07-02 13:05:31.261 | INFO     | src.training.train_model:trainloop:164 - Epoch 8 train 0.3692 test 0.3683 metric ['0.8729', '0.7564']\n",
      "100%|██████████| 45/45 [00:06<00:00,  6.63it/s]\n",
      "2022-07-02 13:05:40.048 | INFO     | src.training.train_model:trainloop:164 - Epoch 9 train 0.2915 test 0.3554 metric ['0.8840', '0.8082']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.58it/s]\n",
      "2022-07-02 13:05:47.470 | INFO     | src.training.train_model:trainloop:164 - Epoch 10 train 0.2300 test 0.3909 metric ['0.8528', '0.7638']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.30it/s]\n",
      "2022-07-02 13:05:54.412 | INFO     | src.training.train_model:trainloop:164 - Epoch 11 train 0.2489 test 0.3610 metric ['0.8750', '0.7962']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.42it/s]\n",
      "2022-07-02 13:06:01.291 | INFO     | src.training.train_model:trainloop:164 - Epoch 12 train 0.2598 test 0.3274 metric ['0.8833', '0.8198']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.41it/s]\n",
      "2022-07-02 13:06:08.172 | INFO     | src.training.train_model:trainloop:164 - Epoch 13 train 0.2324 test 0.3627 metric ['0.8799', '0.7839']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.88it/s]\n",
      "2022-07-02 13:06:15.361 | INFO     | src.training.train_model:trainloop:164 - Epoch 14 train 0.2354 test 0.3238 metric ['0.8917', '0.8080']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.08it/s]\n",
      "2022-07-02 13:06:22.545 | INFO     | src.training.train_model:trainloop:164 - Epoch 15 train 0.2178 test 0.3427 metric ['0.8861', '0.8007']\n",
      "100%|██████████| 45/45 [00:06<00:00,  7.44it/s]\n",
      "2022-07-02 13:06:30.127 | INFO     | src.training.train_model:trainloop:164 - Epoch 16 train 0.2386 test 0.3406 metric ['0.8806', '0.8240']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.06it/s]\n",
      "2022-07-02 13:06:37.197 | INFO     | src.training.train_model:trainloop:164 - Epoch 17 train 0.2267 test 0.3168 metric ['0.8986', '0.8490']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.82it/s]\n",
      "2022-07-02 13:06:44.513 | INFO     | src.training.train_model:trainloop:164 - Epoch 18 train 0.2164 test 0.3209 metric ['0.8951', '0.8033']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.63it/s]\n",
      "2022-07-02 13:06:51.288 | INFO     | src.training.train_model:trainloop:164 - Epoch 19 train 0.1293 test 0.3532 metric ['0.9000', '0.8386']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.89it/s]\n",
      "2022-07-02 13:06:58.542 | INFO     | src.training.train_model:trainloop:164 - Epoch 20 train 0.1027 test 0.3632 metric ['0.8903', '0.8223']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.97it/s]\n",
      "2022-07-02 13:07:05.855 | INFO     | src.training.train_model:trainloop:164 - Epoch 21 train 0.1308 test 0.3165 metric ['0.9028', '0.8430']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.87it/s]\n",
      "2022-07-02 13:07:13.060 | INFO     | src.training.train_model:trainloop:164 - Epoch 22 train 0.1119 test 0.5938 metric ['0.8403', '0.7741']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.09it/s]\n",
      "2022-07-02 13:07:20.205 | INFO     | src.training.train_model:trainloop:164 - Epoch 23 train 0.1265 test 0.3404 metric ['0.9056', '0.8399']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.67it/s]\n",
      "2022-07-02 13:07:27.489 | INFO     | src.training.train_model:trainloop:164 - Epoch 24 train 0.1680 test 0.3212 metric ['0.8958', '0.8455']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.04it/s]\n",
      "2022-07-02 13:07:34.589 | INFO     | src.training.train_model:trainloop:164 - Epoch 25 train 0.1263 test 0.3516 metric ['0.8812', '0.8177']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.81it/s]\n",
      "2022-07-02 13:07:41.948 | INFO     | src.training.train_model:trainloop:164 - Epoch 26 train 0.1203 test 0.3297 metric ['0.8924', '0.8324']\n",
      "100%|██████████| 45/45 [00:06<00:00,  7.49it/s]\n",
      "2022-07-02 13:07:49.599 | INFO     | src.training.train_model:trainloop:164 - Epoch 27 train 0.1393 test 0.3037 metric ['0.8993', '0.8478']\n",
      "100%|██████████| 45/45 [00:06<00:00,  7.37it/s]\n",
      "2022-07-02 13:07:57.244 | INFO     | src.training.train_model:trainloop:164 - Epoch 28 train 0.0499 test 0.3829 metric ['0.9104', '0.8369']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.95it/s]\n",
      "2022-07-02 13:08:04.587 | INFO     | src.training.train_model:trainloop:164 - Epoch 29 train 0.0897 test 0.4108 metric ['0.8799', '0.8153']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.13it/s]\n",
      "2022-07-02 13:08:11.727 | INFO     | src.training.train_model:trainloop:164 - Epoch 30 train 0.0851 test 0.3719 metric ['0.8986', '0.8213']\n",
      "100%|██████████| 45/45 [00:06<00:00,  7.43it/s]\n",
      "2022-07-02 13:08:19.301 | INFO     | src.training.train_model:trainloop:164 - Epoch 31 train 0.0721 test 0.4132 metric ['0.8903', '0.8316']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.71it/s]\n",
      "2022-07-02 13:08:26.821 | INFO     | src.training.train_model:trainloop:164 - Epoch 32 train 0.0845 test 0.4092 metric ['0.8861', '0.8190']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.72it/s]\n",
      "2022-07-02 13:08:34.219 | INFO     | src.training.train_model:trainloop:164 - Epoch 33 train 0.0989 test 0.3533 metric ['0.8986', '0.8488']\n",
      "100%|██████████| 45/45 [00:06<00:00,  7.11it/s]\n",
      "2022-07-02 13:08:42.250 | INFO     | src.training.train_model:trainloop:164 - Epoch 34 train 0.0642 test 0.5251 metric ['0.8771', '0.7710']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.01it/s]\n",
      "2022-07-02 13:08:49.422 | INFO     | src.training.train_model:trainloop:164 - Epoch 35 train 0.0831 test 0.4092 metric ['0.8910', '0.8198']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.77it/s]\n",
      "2022-07-02 13:08:56.898 | INFO     | src.training.train_model:trainloop:164 - Epoch 36 train 0.0989 test 0.3539 metric ['0.8931', '0.8239']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.69it/s]\n",
      "2022-07-02 13:09:04.288 | INFO     | src.training.train_model:trainloop:164 - Epoch 37 train 0.0507 test 0.4159 metric ['0.8944', '0.8185']\n",
      "100%|██████████| 45/45 [00:05<00:00,  7.59it/s]\n",
      "2022-07-02 13:09:11.690 | INFO     | src.training.train_model:trainloop:164 - Epoch 38 train 0.0336 test 0.4630 metric ['0.8979', '0.8434']\n",
      "100%|██████████| 45/45 [00:05<00:00,  8.10it/s]\n",
      "2022-07-02 13:09:18.793 | INFO     | src.training.train_model:trainloop:164 - Epoch 39 train 0.0392 test 0.5689 metric ['0.8736', '0.8097']\n",
      "100%|██████████| 40/40 [04:59<00:00,  7.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=40,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=45,\n",
    "    eval_steps=45,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het model met de attention zorgt voor een lagere loss en een hogere accuracy. De learning rate en de optimizer zijn erg afhankelijk van elkaar. In onderstaande afbeelding zie je de oranje lijn het NLP model zonder attention layer en de blauwe lijn is het NLP model met een attention layer. Wat verder opvalt is dat het er naar uit ziet dat het model nog niet is uitgeleerd. Hierbij is de vervolgstap op de epochs te verhogen (worden verhoogd naar 40). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/NLP_attention_tensorboard.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " De optimizer verander ik niet direct, de Adam optimizer heeft een prijswinnende architect en stopt niet direct bij een mogelijk laag punt, maar kijkt verder. Je ziet op het tensorboard dat de learning rate bij de attention layer nog stabiel blijft ondanks er een scheduler in het model zit. Door de epochs te verhogen naar 40, valt op dat na 30 epochs de learning rate naar beneden gaat door middel van de scheduler (rode lijn onderstaande afbeelding). Minimaal 10 epochs wacht het model voordat deze mogelijk de learning rate verlaagd. Deze wordt dan verlaagt met door middel van de factor 0.9. Om deze reden wordt het aantal epochs nog verder verhoogd naar 100. Dit kost natuurlijk wel meer process tijd en hiermee moet rekening gehouden worden met de afweging om de juiste parameters te bepalen voor het model. In onderstaande afbeelding is het verhogen van de aantal epochs weergegeven. De oranje lijn is de verhoging van de epochs naar 100, hierbij is komt overfitting naar voren wat terug te zien is in de test loss. Daarnaast zie je in de learning rate grafiek dat de scheduler na ongeveer 52 epochs de learning rate met stapjes heeft verlaagd. Hierna heb ik een aantal wijzingen van de learning rate doorgevoerd ( hoger starten: 1e-2), echter zorgt dit niet voor een verbetering van het model. Met de learning rate en optimizer kun je mogelijk direct invloed uitoefenen op het model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/NLP_with_att_overfitting.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aanpassingen van de hidden_size: Deze is op dit moment 128 en deze wil ik met kleine stapjes aanpassen. De accuracy en loss worden negatief beinvloed door minder filters(64). De dataset is niet heel groot en ga de filters nog verhogen naar 256. Dit zorgt er wel voor dat het model langzamer wordt en wanneer de learning rate naar beneden gaat door de scheduler stijgt de loss van de test. Hierbij hou ik de hidden_size op 128, dit geeft helaas geen verbetering van het model en het zorgt ook voor een hoge loss. Onderstaande grafieken tonen de laagste losses en hoogste accuracy (90%) en F1 score (84%).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../figures/result_tensorboard.PNG\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-DDG3aTJy-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef7eee7c1ffccdb050f8336de9a04a9ab88c4d3eb3bee3e0a27c87a184d1d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
