{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "from src.settings import StyleSettings\n",
    "from src.data.data_tools import StyleDataset\n",
    "import numpy as np\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = StyleSettings()\n",
    "traindataset = StyleDataset([settings.trainpath])\n",
    "testdataset = StyleDataset([settings.testpath])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 419 batches in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traindataset) // 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Lace is an openwork fabric , patterned with open holes in the work , made by machine or by hand.',\n",
       " 'wiki')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = traindataset[42]\n",
    "x, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every batch is a `Tuple[str, str]` of a sentence and a label. We can see this is a classification task.\n",
    "The task is, to classify sentences in four categories.\n",
    "Lets build a vocabulary by copy-pasting the code we used before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:03:42.695 | INFO     | src.models.tokenizer:build_vocab:27 - Found 19306 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import tokenizer\n",
    "\n",
    "corpus = []\n",
    "for i in range(len(traindataset)):\n",
    "    x = tokenizer.clean(traindataset[i][0])\n",
    "    corpus.append(x)\n",
    "v = tokenizer.build_vocab(corpus, max=20000)\n",
    "len(v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to cast the labels to an integers. You can use this dictionary to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\"humor\": 0, \"reuters\": 1, \"wiki\": 2, \"proverbs\": 3}\n",
    "d[y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "Figure out, for every class, what accuracy you should expect if the model would guess blind on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'humor': 0.31414510476474533,\n",
       " 'wiki': 0.31175900380284843,\n",
       " 'proverbs': 0.06196405935426143,\n",
       " 'reuters': 0.3121318320781448}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "count_labels = collections.Counter([traindataset[i][1] for  i in range(len(traindataset))])\n",
    "{v: count_labels[v] / len(traindataset) for v in count_labels}\n",
    "# TODO ~ about 4 lines of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geen normaal verdeling > weinig voorbeelden, check embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflect on what you see. What does this mean? What implications does this have? Why is that good/bad?\n",
    "Are there things down the line that could cause a problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Implement a preprocessor\n",
    "\n",
    "We can inherit from `tokenizer.Preprocessor`\n",
    "Only thing we need to adjust is the `cast_label` function.\n",
    " \n",
    "- create a StylePreprocessor class\n",
    "- inherit from Preprocessor\n",
    "- create a new cast_label function for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO ~ about 4 lines of code\n",
    "class StylePreprocessor(tokenizer.Preprocessor):\n",
    "    def cast_label(self, label: str) -> int:\n",
    "        if label in d.keys():\n",
    "            return d[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the preprocessor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = StylePreprocessor(max=100, vocab=v, clean=tokenizer.clean)\n",
    "x=preprocessor([(x, y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the model\n",
    "We can re-use the BaseDatastreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import data_tools\n",
    "\n",
    "trainstreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=traindataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n",
    "teststreamer = data_tools.BaseDatastreamer(\n",
    "    dataset=testdataset, batchsize=32, preprocessor=preprocessor\n",
    ").stream()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   50,  3807,     6,     2,  2422,   516,     8,  1162,    32,    98,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  336,  2136,    76,  5286,     5,     2,   597,     6,     2,   578,\n",
       "           315,     2,   344,    11,     2,   385,  2425,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   25,  1824,    43,  8713,  9417,    61,     2,  4615,  2716,     5,\n",
       "             2,   388,  1744,     2,  4185,   785,     4,  5604,  3426,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    9,    77,   117,    57,    47,  1735,     6,  4427,  9586,    59,\n",
       "           111,    37,    78,   242,     4,    89,     4,     2,  1314,     6,\n",
       "            13,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    9,    12,    21,     2,  4848,    43,    36,   116,   804,   350,\n",
       "            51,     4,    42,     7,   174,     4,  1552,    54,  1579,    59,\n",
       "             9,  2829,    54,    67,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   22,   971,   100,    25,   111,     8,    19,    45, 11706,  1459,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 6915,     8,    15,     6,     2,    50,   129,  9994,     6,     2,\n",
       "            24,  2935,  9995,  6915,  9996,     7,  3771,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  110,   413,  2508,     4,   588,   608,  3040,    17,   158,  2981,\n",
       "            90,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    2,   823,   581,    47,  3424,     6,    15,   257,  5438,   246,\n",
       "         11354,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   18,   244,   742,    46,    63,   384,     3,  2801,    41,    53,\n",
       "           165,    96,   332,  4770,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    5,     2,   293,  5294,   512,     2,   116,    70,  4795,     2,\n",
       "          4834, 18609,   723,   248,     2,  3203,     8,     2, 18610,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   57,    65,  4950,  1056,   592,     5,   639,    10,   358,   449,\n",
       "            21,     2,   398,  1294,    10,     2,   532,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 1150,   528,   263,   391,  2496,     5,  8425,   104,   455,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   33,    20,  3794,  6402,   959,    38, 13000,   239,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 4825,   285,  7714,  2340,  1410,   264,   265,     5,  7131,     5,\n",
       "          3102, 11309,  2164,   867,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  952,   669,     4,   500,    68,   288,   229,  5443,    32, 13858,\n",
       "          2059,   655,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    9,   189,    18,   221, 17001,     5,     7,    83,    47,   269,\n",
       "          1071,   277,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 1832,   254,    32,   441,  2045,    46,   369,  1859,  2321,    55,\n",
       "           841,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 3661,   110,   357,  4960,   555,   419,     5,  1930,    16,  4790,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  257,   474,  1602,     7, 10185,  4475,  1038,    27,  3822,  7028,\n",
       "            85,    47,   196,   100,   181,     6,     2,  2017,   176,     7,\n",
       "           196,  7029,     6,     3,  5441,    71, 10186,     0,     0,     0,\n",
       "             0],\n",
       "        [    2,    24,   204,     6,     2,  1597,    12, 10319,   136,    11,\n",
       "         10320,    10,    23,   449,    17,   381,     6,  2589,    20,  5509,\n",
       "          1488,  2375,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    9,   240,     4,     2,  1186,     2,    87,    72,     7,     9,\n",
       "            83,    27,    14,    95,   622,    10,  1023,    59,    22,   453,\n",
       "            42,     3,  6103,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   64,    65,     2,  5317,  3420,    28,   807,    22,  1703,    28,\n",
       "          1147,   131,    13,    12,  1730,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    2,   440,  3509,     6,  1691,   383,   827, 11317, 11318, 11319,\n",
       "           969,   383,     7,   729,   383,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   13,     8,   100,   223,    10,    41, 13348, 13349,    21,  1691,\n",
       "           514,  1331,     4,  8663,     3,   618,     5,  1518,   551,    71,\n",
       "            92,    15,    21,     3,    40,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 6288,    36,  1487,  1373,  3618,    53,     3,   399,   893,  2367,\n",
       "          7108,     3,   374,     6,   192,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  123,  1454,   955,   617,   782,  3232,    10,   821,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  345,   464,     5,  1403,  2467,    26, 16949,   511,  1274,  1498,\n",
       "          1631,  5123,     5,     3,  1334,     5,     2,   649,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [  891,   939,  9859,  9524,   488,   110,  1205,   121, 18522,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [ 1523,  2494, 18803,  2155,  1312,     5,  6619,  1440,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [   14,    69,   688,    71,  1258,    16,   892,    92,    16, 17519,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0],\n",
       "        [    2, 17548,   486,   803,     6,     2,    23,  4263,  1889,  4014,\n",
       "             2,  8931,     6,     2, 17549,     7,  2697, 17550,    90,    81,\n",
       "             3,   329,  3651,  1427,    10,     2,    24,    40,   300,  5695,\n",
       "          2317]], dtype=torch.int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer)\n",
    "x.shape, y\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 : Metrics, loss\n",
    "Select proper metrics and a loss function.\n",
    "\n",
    "Bonus: implement an additional metric function that is relevant for this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import metrics\n",
    "import torch\n",
    "# TODO ~ 2 lines of code\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "metrics = [metrics.F1Score()]\n",
    "#metrics = metrics.Accuracy()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opbasis van theorie MASE en crossentropyloss(). Next step misschien mogelijk metrics 2 toevoegen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 : Basemodel\n",
    "Create a base model. It does not need to be naive; you could re-use the\n",
    "NLP models we used for the IMDB.\n",
    "\n",
    "I suggest to start with a hidden size of about 128.\n",
    "Use a config dictionary, or a gin file, both are fine.\n",
    "\n",
    "Bonus points if you create a Trax model in src.models, and even more if you add a trax training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_dir = settings.log_dir\n",
    "# TODO between 2 and 8 lines of code, depending on your setup\n",
    "# Assuming you load your model in one line of code from src.models.rnn\n",
    "config = {\n",
    "    \"vocab\": len(v),\n",
    "    \"hidden_size\": 128,\n",
    "    \"num_layers\": 3,\n",
    "    \"dropout\": 0.1,\n",
    "    \"output_size\": 4,\n",
    "}\n",
    "from src.models import rnn\n",
    "model = rnn.NLPmodel(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the trainloop.\n",
    "\n",
    "- Give the lenght of the traindataset, how many batches of 32 can you get out of it?\n",
    "- If you take a short amount of train_steps (eg 25) for every epoch, how many epochs do you need to cover the complete dataset?\n",
    "- What amount of epochs do you need to run the loop with trainsteps=25 to cover the complete traindataset once? \n",
    "- answer the questions above, and pick a reasonable epoch lenght\n",
    "\n",
    "Start with a default learning_rate of 1e-3 and an Adam optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-23 11:10:17.182 | INFO     | src.data.data_tools:dir_add_timestamp:66 - Logging to ../tune/20220623-1110\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.66it/s]\n",
      "  0%|          | 0/1 [00:09<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Accuracy' object is not iterable\n  In call to configurable 'trainloop' (<function trainloop at 0x7f1081f4aa60>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb Cell 30'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msrc\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m train_model\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m train_model\u001b[39m.\u001b[39;49mtrainloop(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=3'>4</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=4'>5</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=5'>6</a>\u001b[0m     metrics\u001b[39m=\u001b[39;49mmetrics,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=6'>7</a>\u001b[0m     optimizer\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=7'>8</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=8'>9</a>\u001b[0m     loss_fn\u001b[39m=\u001b[39;49mloss_fn,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=9'>10</a>\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrainstreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=10'>11</a>\u001b[0m     test_dataloader\u001b[39m=\u001b[39;49mteststreamer,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=11'>12</a>\u001b[0m     log_dir\u001b[39m=\u001b[39;49mlog_dir,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=12'>13</a>\u001b[0m     train_steps\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=13'>14</a>\u001b[0m     eval_steps\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml-lab-499b0cc0-f0fa-444d-a905-b2d2bead7477.westeurope.cloudapp.azure.com/home/mladmin/code/examen-22/notebooks/02_style_detection.ipynb#ch0000029vscode-remote?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-DDG3aTJy-py3.9/lib/python3.9/site-packages/gin/config.py:1605\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m scope_info \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m in scope \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(scope_str) \u001b[39mif\u001b[39;00m scope_str \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1604\u001b[0m err_str \u001b[39m=\u001b[39m err_str\u001b[39m.\u001b[39mformat(name, fn_or_cls, scope_info)\n\u001b[0;32m-> 1605\u001b[0m utils\u001b[39m.\u001b[39;49maugment_exception_message_and_reraise(e, err_str)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-DDG3aTJy-py3.9/lib/python3.9/site-packages/gin/utils.py:41\u001b[0m, in \u001b[0;36maugment_exception_message_and_reraise\u001b[0;34m(exception, message)\u001b[0m\n\u001b[1;32m     39\u001b[0m proxy \u001b[39m=\u001b[39m ExceptionProxy()\n\u001b[1;32m     40\u001b[0m ExceptionProxy\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(exception)\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[39mraise\u001b[39;00m proxy\u001b[39m.\u001b[39mwith_traceback(exception\u001b[39m.\u001b[39m__traceback__) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/exam-22-DDG3aTJy-py3.9/lib/python3.9/site-packages/gin/config.py:1582\u001b[0m, in \u001b[0;36m_make_gin_wrapper.<locals>.gin_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1579\u001b[0m new_kwargs\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[1;32m   1581\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1582\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m   1583\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m   err_str \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/code/examen-22/notebooks/../src/training/train_model.py:143\u001b[0m, in \u001b[0;36mtrainloop\u001b[0;34m(epochs, model, optimizer, learning_rate, loss_fn, metrics, train_dataloader, test_dataloader, log_dir, train_steps, eval_steps, patience, factor, tunewriter)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(epochs)):\n\u001b[1;32m    139\u001b[0m     train_loss \u001b[39m=\u001b[39m trainbatches(\n\u001b[1;32m    140\u001b[0m         model, train_dataloader, loss_fn, optimizer_, train_steps\n\u001b[1;32m    141\u001b[0m     )\n\u001b[0;32m--> 143\u001b[0m     metric_dict, test_loss \u001b[39m=\u001b[39m evalbatches(\n\u001b[1;32m    144\u001b[0m         model, test_dataloader, loss_fn, metrics, eval_steps\n\u001b[1;32m    145\u001b[0m     )\n\u001b[1;32m    147\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n\u001b[1;32m    149\u001b[0m     \u001b[39mif\u001b[39;00m tunewriter:\n",
      "File \u001b[0;32m~/code/examen-22/notebooks/../src/training/train_model.py:65\u001b[0m, in \u001b[0;36mevalbatches\u001b[0;34m(model, testdatastreamer, loss_fn, metrics, eval_steps)\u001b[0m\n\u001b[1;32m     63\u001b[0m     yhat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     64\u001b[0m     test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(yhat, y)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m metrics:\n\u001b[1;32m     66\u001b[0m         metric_dict[\u001b[39mstr\u001b[39m(m)] \u001b[39m=\u001b[39m (\n\u001b[1;32m     67\u001b[0m             metric_dict\u001b[39m.\u001b[39mget(\u001b[39mstr\u001b[39m(m), \u001b[39m0.0\u001b[39m) \u001b[39m+\u001b[39m m(y, yhat)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     68\u001b[0m         )\n\u001b[1;32m     70\u001b[0m test_loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m eval_steps\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Accuracy' object is not iterable\n  In call to configurable 'trainloop' (<function trainloop at 0x7f1081f4aa60>)"
     ]
    }
   ],
   "source": [
    "from src.training import train_model\n",
    "\n",
    "model = train_model.trainloop(\n",
    "    epochs=1,\n",
    "    model=model,\n",
    "    metrics=metrics,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    learning_rate=1e-3,\n",
    "    loss_fn=loss_fn,\n",
    "    train_dataloader=trainstreamer,\n",
    "    test_dataloader=teststreamer,\n",
    "    log_dir=log_dir,\n",
    "    train_steps=25,\n",
    "    eval_steps=25,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save an image from the training in tensorboard in the `figures` folder.\n",
    "Explain what you are seeing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your explanation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Evaluate the basemodel\n",
    "Create a confusion matrix with the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for _ in range(10):\n",
    "    X, y = next(teststreamer)\n",
    "    yhat = model(X)\n",
    "    yhat = yhat.argmax(dim=1)\n",
    "    y_pred.append(yhat.tolist())\n",
    "    y_true.append(y.tolist())\n",
    "\n",
    "yhat = [x for y in y_pred for x in y]\n",
    "y = [x for y in y_true for x in y]\n",
    "\n",
    "cfm = confusion_matrix(y, yhat)\n",
    "cfm_norm = cfm / np.sum(cfm, axis=1, keepdims=True)\n",
    "plot = sns.heatmap(cfm_norm, annot=cfm_norm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save this in the figures folder.\n",
    "Interpret this. \n",
    "\n",
    "- What is going on?\n",
    "- What is a good metric here?\n",
    "- how is your answer to Q1 relevant here?\n",
    "- Is there something you could do to fix/improve things, after you see these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Tune the model\n",
    "Don't overdo this.\n",
    "More is not better.\n",
    "\n",
    "Bonus points for things like:\n",
    "- Attention layers\n",
    "- Trax architecture including a functioning training loop\n",
    "\n",
    "Keep it small! It's better to present 2 or 3 sane experiments that are structured and thought trough, than 25 random guesses. You can test more, but select 2 or 3 of the best alternatives you researched, with a rationale why this works better.\n",
    "\n",
    "Keep it concise; explain:\n",
    "- what you changed\n",
    "- why you thought that was a good idea  \n",
    "- what the impact was (visualise or numeric)\n",
    "- explain the impact\n",
    "\n",
    "You dont need to get a perfect score; curiousity driven research that fails is fine.\n",
    "The insight into what is happening is more important than the quantity.\n",
    "\n",
    "Keep logs of your settings;\n",
    "either use gin, or save configs, or both :)\n",
    "Store images in the `figures` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('exam-22-DDG3aTJy-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ef7eee7c1ffccdb050f8336de9a04a9ab88c4d3eb3bee3e0a27c87a184d1d38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
